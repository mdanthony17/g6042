{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy, scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keeps plots inside shell\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/computation/__init__.py:19: UserWarning: The installed version of numexpr 2.4.4 is not supported in pandas and will be not be used\n",
      "\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Binomial Distribution__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bernouli trial is just a fancy name for an experiment \n",
    "# with two possible outcomes given by a fixed probability\n",
    "# ex: coin flip\n",
    "def perform_bernouli_trials(num_trials, prob_success):\n",
    "    num_successes = 0\n",
    "    for i in xrange(num_trials):\n",
    "        if np.random.rand() < prob_success:\n",
    "            num_successes +=1\n",
    "            \n",
    "    return num_successes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Binomial describes the distribution of successes of \n",
    "# a fixed number of Bernouli trials\n",
    "# ex: what is probability of getting 2 heads in 10 coin flips\n",
    "# num_expts describes each game where I flip 10 coins\n",
    "num_expts = 10 # number of experiments we will perform\n",
    "num_trials = 10 # number of coin flips per experiment\n",
    "prob_success = 0.5\n",
    "\n",
    "# we will use a List to keep track of the number of successes in each experiment\n",
    "# if you can, always initialize your list instead of appending to it\n",
    "l_num_successes = [0 for i in xrange(num_expts)]\n",
    "for i in xrange(num_expts):\n",
    "    l_num_successes[i] = perform_bernouli_trials(num_trials, prob_success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIhJAKncRkQBSuYuIBND/B6YafQ/1mL0MAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108899150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# \"_ = \" just hides the output in matplotlib by saving\n",
    "# what is returned in a variable we won't ever use\n",
    "_ = plt.hist(l_num_successes, bins=11, range=(-0.5, 10.5), normed=True)\n",
    "a_possible_successes = np.linspace(0, 10, 11)\n",
    "a_prob = scipy.stats.binom.pmf(a_possible_successes, num_trials, prob_success)\n",
    "_ = plt.plot(a_possible_successes, a_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should play with the number of experiments - how do you expect the relationship between the theoretical and our experimental distribution to change as we increase the number of statistics? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Poisson Distribution__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Poisson distribution is a discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time and/or space if these events occur with a known average rate and independently of the time since the last event.  What does this jargon really mean though?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Poisson distribution, in its most basic form is an approximation of the Binomial distribution.  You can actually easily derive the complicated expression for the Poisson distribution by breaking down a given time intervals into small enough chunks such that they can be thought of as individual Bernouli trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More specifically, you can use the Poisson distribution to approximate a binomial distribution as the number of trials goes to infinity and the success probability goes to zero.  In reality, for macroscopic situations, you don't really need to consider the Poisson distribution as an approximation and can typically just use the rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how can we predict the number of tweets Trump will send out in a day?\n",
    "# 12/11/16-2/8/17\n",
    "l_num_tweets = [6, 9, 6, 1, 6, 4, 7, 1, 5, 3, 4, 5, 6, 4, 2, 5, 2, 4, 1, \n",
    "                3, 3, 6, 7, 11, 9, 9, 11, 7, 6, 8, 6, 6, 4, 8, 5, 8, 4, \n",
    "                10, 10, 8, 11, 3, 4, 1, 8, 8, 6, 7, 4, 7, 8, 4, 4, 6, 8, 10, 4, 6, 3, 4]\n",
    "# we will use the arithmentic mean to approximate the mean of the Poisson distribution\n",
    "avg_num_tweets = np.mean(l_num_tweets)\n",
    "# notice that I am forcefully setting an upper limit on the range\n",
    "# but in theory the distribution continues to infinity\n",
    "a_possible_tweets = np.linspace(0, 12, 13)\n",
    "a_prob_num_tweets = scipy.stats.poisson.pmf(a_possible_tweets, avg_num_tweets)\n",
    "_ = plt.hist(l_num_tweets, bins=13, range=(-0.5, 12.5), normed=True)\n",
    "_ = plt.plot(a_possible_tweets, a_prob_num_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# on a serious note, let's use an example from physics\n",
    "# let's say 10M particles pass through your detector and\n",
    "# the probability of detecting a single particle is 1e-6 (0.0001%)\n",
    "# what does your distribution look like?\n",
    "num_particles = 1e7\n",
    "prob_detection = 1e-6\n",
    "a_possible_num_particles = np.linspace(0, int(3*num_particles*prob_detection), int(3*num_particles*prob_detection)+1)\n",
    "a_probs_binom = scipy.stats.binom.pmf(a_possible_num_particles, num_particles, prob_detection)\n",
    "# parameter for Poisson is the mean so let's use the expectation value of\n",
    "# the Binomial distribution \\mu = n*p\n",
    "a_probs_poisson = scipy.stats.poisson.pmf(a_possible_num_particles, num_particles*prob_detection)\n",
    "_ = plt.plot(a_possible_num_particles, a_probs_binom, 'g-')\n",
    "_ = plt.plot(a_possible_num_particles, a_probs_poisson, 'b--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Gaussian Distribution's Relation to Binomial and Poisson Distributions__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you all have likely dealt with the normal distribution before, we're not going to spend a lot of time on it.. Instead, we will talk about the relationship it has with the binomial and poisson distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that you need to be careful about though is the fact that both the binomial and Poisson distributions are discrete while a gaussian is a continuous distribution.  When drawing random numbers (something we will get to later) this is not usually a large issue (one can simply round with little associated error) but when talking about probabilities you must be very careful.  Also note that while both the binomial and Poisson distributions can only assign a probability to values greater than zero, the gaussian has a non-zero PDF at all points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will start with the binomial distribution.  The binomial distribution can be approximated by a gaussian as the number of trials becomes very large.  You do not need an assertion on the the probability of success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# same example as above with increased probability\n",
    "num_particles = 1e7\n",
    "prob_detection = 1e-3\n",
    "\n",
    "binom_mean = num_particles*prob_detection\n",
    "binom_std = (num_particles*prob_detection*(1-prob_detection))**0.5\n",
    "lb_plot = int(binom_mean - 4*binom_std)\n",
    "ub_plot = int(binom_mean + 4*binom_std)\n",
    "\n",
    "a_possible_num_particles = np.linspace(lb_plot, ub_plot, \n",
    "                                       (ub_plot - lb_plot)+1)\n",
    "a_probs_binom = scipy.stats.binom.pmf(a_possible_num_particles, num_particles, prob_detection)\n",
    "# parameter for Poisson is the mean so let's use the expectation value of\n",
    "# the Binomial distribution \\mu = n*p\n",
    "a_probs_normal = scipy.stats.norm.pdf(a_possible_num_particles, binom_mean, binom_std)\n",
    "_ = plt.plot(a_possible_num_particles, a_probs_binom, 'g-')\n",
    "_ = plt.plot(a_possible_num_particles, a_probs_normal, 'r--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forgetting about the binomial distribution momentarily, we can also examine the normal approximation of the Poisson distribution.  Here, the only requirement is that our single parameter, mu, is large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poisson_mean = 1000\n",
    "poisson_std = poisson_mean**0.5\n",
    "\n",
    "lb_plot = int(poisson_mean - 4*poisson_std)\n",
    "ub_plot = int(poisson_mean + 4*poisson_std)\n",
    "\n",
    "a_points = np.linspace(lb_plot, ub_plot, (ub_plot - lb_plot)+1)\n",
    "a_probs_poisson = scipy.stats.poisson.pmf(a_points, poisson_mean)\n",
    "a_probs_normal = scipy.stats.norm.pdf(a_points, poisson_mean, poisson_std)\n",
    "\n",
    "_ = plt.plot(a_points, a_probs_poisson, 'b-')\n",
    "_ = plt.plot(a_points, a_probs_normal, 'r--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proving these approximations is one of those problems that every physicist should do once in their life so I highly encourage you to give it a try!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Unbinned Likelihood Fit__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While useful, an unbinned likelihood fit (like the one we will perform in this example) are less common in physics.  On the other hand, they are definitely worth seeing and will hopefully help you get a better understanding of maximum likelihood estimation in theory and in practice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seemingly contradicting the above, unbinned analyses are typically preferred because they are more precise.  When you bin data in a histogram, you are losing information!  However, in physics, you are typically dealing with huge datasets so you must sacrifice some of the information for practical purposes.  Usually the effect of binning is very small though so it's not a big issue.  Also, unbinned analyses are only practical where you can talk about a PDF at every point in the space you care about.  Most times you can get around this by approximating the PDF with some gaussian mixture but sometimes you can't.  While this lack of an analytical model makes analyses much more difficult for binned data, they are still possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the tutorial we will fit for both parameters of a gaussian.  We will create our data via simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "true_mean = 30\n",
    "true_std = 6\n",
    "num_data_pts = 200\n",
    "random_seed = 0\n",
    "\n",
    "lb_plot = true_mean - 4*true_std\n",
    "ub_plot = true_mean + 4*true_std\n",
    "\n",
    "a_data = scipy.stats.norm.rvs(loc=true_mean, scale=true_std, size=num_data_pts, random_state=random_seed)\n",
    "\n",
    "_ = plt.hist(a_data, bins=20, range=(lb_plot, ub_plot), normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now we need to define the likelihood function\n",
    "# since all points are drawn from the same distribution \n",
    "# (unlike our example from last week), our function \n",
    "# is much simpler\n",
    "def ln_likelihood_normal(a_data, mean_test, std_test):\n",
    "    #print a_data\n",
    "    #print mean_test, std_test\n",
    "    return np.sum(scipy.stats.norm.logpdf(a_data, loc=mean_test, scale=std_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_parameter_pts = 50\n",
    "percent_level_away = 0.1\n",
    "a_means = np.linspace(true_mean*(1-percent_level_away/2.), true_mean*(1+percent_level_away/2.), num_parameter_pts)\n",
    "a_stds = np.linspace(true_std*(1-percent_level_away), true_std*(1+percent_level_away), num_parameter_pts)\n",
    "a_means, a_stds = np.meshgrid(a_means, a_stds)\n",
    "# convert arrays to 50x50 arrays\n",
    "\n",
    "a_likelihoods = np.zeros(a_means.shape)\n",
    "\n",
    "for index, _ in np.ndenumerate(a_means):\n",
    "    a_likelihoods[index] = ln_likelihood_normal(a_data, a_means[index], a_stds[index])\n",
    "    \n",
    "max_likelihood = np.max(a_likelihoods)\n",
    "max_args = np.unravel_index(np.argmax(a_likelihoods), a_likelihoods.shape)\n",
    "a_likelihoods = 2*(max_likelihood - a_likelihoods)\n",
    "\n",
    "l_levels = [1, 2, 3]\n",
    "c_likelihood = plt.contour(a_means, a_stds, a_likelihoods, l_levels)\n",
    "_ = plt.clabel(c_likelihood, inline=1, fontsize=10, fmt='%.1f')\n",
    "_ = plt.title(r'$2 \\Delta ln(L)$')\n",
    "_ = plt.xlabel('Mean')\n",
    "_ = plt.ylabel('Std')\n",
    "\n",
    "_ = plt.scatter(true_mean, true_std, marker='x', s=80)\n",
    "#_ = plt.annotate('True Value', xy=(true_mean, true_std))\n",
    "\n",
    "_ = plt.scatter(a_means[max_args], a_stds[max_args], marker='o', s=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do we deal with the uncertainty on our best fit parameters?  It's not as straight forward as before!  Now we have a circle of points at 1/2 below the maximum log-likelihood.  The simplest, but least correct way to handle this, is to project into 1 dimension for each parameter and treat the uncertainties as independent.  A much better way of handling the uncertainty, though, is to approximate our likelihood function as a 2D gaussian and use our likelihood measurements in the grid to determine the covariance matrix.  Remember, nothing says that the uncertainties of the two parameters will not be related.  In fact, quite generally there will be a correlation between the two uncertainties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In practice, when you use any sort of software package the covariance matrix will be estiamted for you!  It's up to you to determine if the covariance matrix is appropriate though..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Questions__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Can you see any major downside to how we are finding the maximum likelihood?\n",
    "2.  Can you explain what our innermost contour represents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
